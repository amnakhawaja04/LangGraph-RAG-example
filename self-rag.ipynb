{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653cc825-dbb6-4fd6-a19e-0904238946a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: langgraph in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: chromadb in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.7)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.12.5)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.2.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (0.3.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (8.3.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.6)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-huggingface) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2024.5.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.66.4)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (0.9.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb) (4.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.18.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\pmls\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community langchain-huggingface langgraph chromadb sentence-transformers pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75319454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PMLS\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langgraph.graph import StateGraph, START, END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f6937-2cf5-4e0a-a10e-78aabc3b5a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee9d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeTextLoader:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def lazy_load(self):\n",
    "        try:\n",
    "            with open(self.file_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                yield Document(\n",
    "                    page_content=f.read(),\n",
    "                    metadata={\"source\": self.file_path}\n",
    "                )\n",
    "        except Exception:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2620e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"C:\\Users\\PMLS\\Downloads\\langgraph\\lmkr_data\"\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    DATA_PATH,\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=SafeTextLoader\n",
    ")\n",
    "\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c64ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "doc_splits = splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8528ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PMLS\\AppData\\Local\\Temp\\ipykernel_14144\\3706897807.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(doc_splits, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94cc0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "base_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    task=\"conversational\",        # ðŸ”‘ CRITICAL\n",
    "    temperature=0,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "\n",
    "llm = ChatHuggingFace(llm=base_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03ac8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question using ONLY the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = rag_prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "20246d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocRelevance(BaseModel):\n",
    "    binary_score: str\n",
    "\n",
    "doc_relevance_parser = JsonOutputParser(\n",
    "    pydantic_object=DocRelevance\n",
    ")\n",
    "\n",
    "doc_relevance_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a strict binary classifier.\\n\"\n",
    "     \"Respond with ONLY valid JSON.\\n\"\n",
    "     '{{ \"binary_score\": \"yes\" | \"no\" }}'),\n",
    "    (\"human\",\n",
    "     \"Question:\\n{question}\\n\\nDocument:\\n{document}\")\n",
    "])\n",
    "\n",
    "doc_relevance_grader = doc_relevance_prompt | llm | JsonOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88b62aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Groundedness(BaseModel):\n",
    "    binary_score: str\n",
    "\n",
    "grounded_parser = JsonOutputParser(pydantic_object=Groundedness)\n",
    "\n",
    "grounded_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are checking whether the answer is grounded in the documents.\\n\"\n",
    "     \"Respond ONLY in JSON.\\n\"\n",
    "     '{{ \"binary_score\": \"yes\" | \"no\" }}'),\n",
    "    (\"human\",\n",
    "     \"Documents:\\n{documents}\\n\\nAnswer:\\n{generation}\")\n",
    "])\n",
    "\n",
    "grounded_grader = grounded_prompt | llm | JsonOutputParser()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8323031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerUsefulness(BaseModel):\n",
    "    binary_score: str\n",
    "\n",
    "usefulness_parser = JsonOutputParser(pydantic_object=AnswerUsefulness)\n",
    "\n",
    "usefulness_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Check whether the answer addresses the question.\\n\"\n",
    "     \"Respond ONLY in JSON.\\n\"\n",
    "     '{{ \"binary_score\": \"yes\" | \"no\" }}'),\n",
    "    (\"human\",\n",
    "     \"Question:\\n{question}\\n\\nAnswer:\\n{generation}\")\n",
    "])\n",
    "\n",
    "usefulness_grader = usefulness_prompt | llm | JsonOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ac0ea5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Rewrite the question to improve document retrieval.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "question_rewriter = rewrite_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7d9aec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: list\n",
    "    generation: str\n",
    "    steps: List[str]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3913bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: GraphState):\n",
    "    steps = state.get(\"steps\", [])\n",
    "    steps.append(\"\\n---RETRIEVE---\")\n",
    "    steps.append(\"Node 'retrieve':\")\n",
    "\n",
    "    docs = retriever.invoke(state[\"question\"])\n",
    "\n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"documents\": docs,\n",
    "        \"steps\": steps,\n",
    "    }\n",
    "\n",
    "\n",
    "def grade_documents(state: GraphState):\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"\\n---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "\n",
    "    filtered_docs = []\n",
    "\n",
    "    for d in state[\"documents\"]:\n",
    "        score = doc_relevance_grader.invoke({\n",
    "            \"question\": state[\"question\"],\n",
    "            \"document\": d.page_content\n",
    "        })\n",
    "\n",
    "        steps.append(\n",
    "            f\"---GRADE: DOCUMENT {'RELEVANT' if score['binary_score']=='yes' else 'NOT RELEVANT'}---\"\n",
    "        )\n",
    "\n",
    "        if score[\"binary_score\"] == \"yes\":\n",
    "            filtered_docs.append(d)\n",
    "\n",
    "    steps.append(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"documents\": filtered_docs,\n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"\\n---GENERATE---\")\n",
    "\n",
    "    generation = rag_chain.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": format_docs(state[\"documents\"]),\n",
    "    })\n",
    "\n",
    "    steps.append(\"---CHECK HALLUCINATIONS---\")\n",
    "\n",
    "    grounded = grounded_grader.invoke({\n",
    "        \"documents\": format_docs(state[\"documents\"]),\n",
    "        \"generation\": generation,\n",
    "    })\n",
    "\n",
    "\n",
    "    if grounded[\"binary_score\"] != \"yes\":\n",
    "        steps.append(\"---DECISION: GENERATION IS NOT GROUNDED---\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"generation\": generation,\n",
    "            \"steps\": steps,\n",
    "            \"__route__\": \"regenerate\",\n",
    "        }\n",
    "\n",
    "    steps.append(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "    steps.append(\"---GRADE GENERATION VS QUESTION---\")\n",
    "\n",
    "    useful = usefulness_grader.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"generation\": generation,\n",
    "    })\n",
    "\n",
    "    if useful[\"binary_score\"] == \"yes\":\n",
    "        steps.append(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"generation\": generation,\n",
    "            \"steps\": steps,\n",
    "            \"__route__\": \"end\",   \n",
    "        }\n",
    "\n",
    "    steps.append(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "    return {\n",
    "        **state,\n",
    "        \"generation\": generation,\n",
    "        \"steps\": steps,\n",
    "        \"__route__\": \"rewrite\",  \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    return {\n",
    "        \"question\": question_rewriter.invoke({\"question\": state[\"question\"]}),\n",
    "        \"documents\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "69561d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    # AFTER document grading\n",
    "    if not state[\"documents\"]:\n",
    "        return \"transform_query\"\n",
    "    return \"generate\"\n",
    "\n",
    "\n",
    "def decide_after_generation(state):\n",
    "    # hallucination check\n",
    "    if not state[\"grounded\"]:\n",
    "        return \"regenerate\"\n",
    "\n",
    "    # usefulness check\n",
    "    if not state[\"useful\"]:\n",
    "        return \"transform_query\"\n",
    "\n",
    "    return \"end\"\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "\n",
    "def grade_generation(state):\n",
    "    grounded = grounded_grader.invoke({\n",
    "        \"documents\": format_docs(state[\"documents\"]),\n",
    "        \"generation\": state[\"generation\"]\n",
    "    })\n",
    "\n",
    "    if grounded[\"binary_score\"] != \"yes\":\n",
    "        return \"generate\"  \n",
    "\n",
    "    useful = usefulness_grader.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"generation\": state[\"generation\"]\n",
    "    })\n",
    "\n",
    "    if useful[\"binary_score\"] == \"yes\":\n",
    "        return \"useful\"    \n",
    "\n",
    "    return \"transform_query\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"retrieve\", retrieve)\n",
    "graph.add_node(\"grade_documents\", grade_documents)\n",
    "graph.add_node(\"generate\", generate)\n",
    "graph.add_node(\"transform_query\", transform_query)\n",
    "\n",
    "graph.add_edge(START, \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"transform_query\": \"transform_query\",\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    decide_after_generation,\n",
    "    {\n",
    "        \"regenerate\": \"generate\",\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"end\": END,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0ac5ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION VS QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\n",
      "---FINAL ANSWER---\n",
      "\n",
      "content=' LMKR is a petroleum technology company providing reservoir-centric interpretation, modeling and analytics software, mobile technology solutions, and E&P data services. Their offerings aim to lower the risk in the exploration and production of both conventional and unconventional resource plays.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 0, 'total_tokens': 59}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b21e0-37bd-7a33-a60e-c383c2ebda2a-0' usage_metadata={'input_tokens': 0, 'output_tokens': 59, 'total_tokens': 59}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result = app.invoke({\n",
    "    \"question\": \"What are the product and services of lmkr?\"\n",
    "})\n",
    "\n",
    "# Print execution trace\n",
    "for step in result[\"steps\"]:\n",
    "    print(step)\n",
    "\n",
    "print(\"\\n---FINAL ANSWER---\\n\")\n",
    "print(result[\"generation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d1c63848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION VS QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\n",
      "---FINAL ANSWER---\n",
      "\n",
      "content=' Atif Rais Khan is the CEO of LMKR.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 0, 'total_tokens': 14}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b21e9-2bad-7e00-886c-d9fe43180939-0' usage_metadata={'input_tokens': 0, 'output_tokens': 14, 'total_tokens': 14}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result = app.invoke({\n",
    "    \"question\": \"Who is the ceo of lmkr?\"\n",
    "})\n",
    "\n",
    "# Print execution trace\n",
    "for step in result[\"steps\"]:\n",
    "    print(step)\n",
    "\n",
    "print(\"\\n---FINAL ANSWER---\\n\")\n",
    "print(result[\"generation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "88ba1c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION VS QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\n",
      "---FINAL ANSWER---\n",
      "\n",
      "content=' LMKR was founded in 1994.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 0, 'total_tokens': 13}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b21ea-01d8-7360-a98a-98417a125287-0' usage_metadata={'input_tokens': 0, 'output_tokens': 13, 'total_tokens': 13}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result = app.invoke({\n",
    "    \"question\": \"When was lmkr founded?\"\n",
    "})\n",
    "\n",
    "# Print execution trace\n",
    "for step in result[\"steps\"]:\n",
    "    print(step)\n",
    "\n",
    "print(\"\\n---FINAL ANSWER---\\n\")\n",
    "print(result[\"generation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6784e07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_score': 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_relevance_grader.invoke({\n",
    "    \"question\": \"What products does LMKR offer?\",\n",
    "    \"document\": documents[0].page_content\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1885f85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS NOT GROUNDED---\n",
      "\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION VS QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION VS QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\n",
      "---FINAL ANSWER---\n",
      "\n",
      "content=' GVERSE is a revolutionary suite of applications offered by LMKR that focuses on workflow optimization and productivity while minimizing risks in the geoscience industry. It is designed to be inter-operable with other known geoscience software suites and offers quick visualization, streamlined workflows, and maximizes the value of data. GVERSE is available worldwide and was first released in November 2015. It provides actionable intelligence for asset teams and covers everything from prospect generation to field development. Applications can be purchased and downloaded through the GVERSE E-STORE. LMKR is a technology company with a broad portfolio of solutions that includes geoscience exploration, intelligent transportation, data management, and consulting services.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 160, 'prompt_tokens': 0, 'total_tokens': 160}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b21eb-71b1-7b41-9554-fe8ec9c52fe9-0' usage_metadata={'input_tokens': 0, 'output_tokens': 160, 'total_tokens': 160}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result = app.invoke({\n",
    "    \"question\": \"What is gverse?\"\n",
    "})\n",
    "\n",
    "# Print execution trace\n",
    "for step in result[\"steps\"]:\n",
    "    print(step)\n",
    "\n",
    "print(\"\\n---FINAL ANSWER---\\n\")\n",
    "print(result[\"generation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d8d12c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"mermaid-container\"></div>\n",
       "\n",
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js\"></script>\n",
       "<script>\n",
       "require.config({\n",
       "    paths: {\n",
       "        mermaid: \"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min\"\n",
       "    }\n",
       "});\n",
       "\n",
       "require([\"mermaid\"], function(mermaid) {\n",
       "    mermaid.initialize({\n",
       "        startOnLoad: false,\n",
       "        theme: \"default\",\n",
       "        flowchart: { curve: \"linear\" }\n",
       "    });\n",
       "    document.getElementById(\"mermaid-container\").innerHTML =\n",
       "        `<pre class=\"mermaid\">---\n",
       "config:\n",
       "  flowchart:\n",
       "    curve: linear\n",
       "---\n",
       "graph TD;\n",
       "\t__start__([<p>__start__</p>]):::first\n",
       "\tretrieve(retrieve)\n",
       "\tgrade_documents(grade_documents)\n",
       "\tgenerate(generate)\n",
       "\ttransform_query(transform_query)\n",
       "\t__end__([<p>__end__</p>]):::last\n",
       "\t__start__ --> retrieve;\n",
       "\tgenerate -. &nbsp;end&nbsp; .-> __end__;\n",
       "\tgenerate -.-> transform_query;\n",
       "\tgrade_documents -.-> generate;\n",
       "\tgrade_documents -.-> transform_query;\n",
       "\tretrieve --> grade_documents;\n",
       "\ttransform_query --> retrieve;\n",
       "\tgenerate -. &nbsp;regenerate&nbsp; .-> generate;\n",
       "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
       "\tclassDef first fill-opacity:0\n",
       "\tclassDef last fill:#bfb6fc\n",
       "</pre>`;\n",
       "    mermaid.run();\n",
       "});\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "mermaid = app.get_graph().draw_mermaid()\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<div id=\"mermaid-container\"></div>\n",
    "\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js\"></script>\n",
    "<script>\n",
    "require.config({{\n",
    "    paths: {{\n",
    "        mermaid: \"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min\"\n",
    "    }}\n",
    "}});\n",
    "\n",
    "require([\"mermaid\"], function(mermaid) {{\n",
    "    mermaid.initialize({{\n",
    "        startOnLoad: false,\n",
    "        theme: \"default\",\n",
    "        flowchart: {{ curve: \"linear\" }}\n",
    "    }});\n",
    "    document.getElementById(\"mermaid-container\").innerHTML =\n",
    "        `<pre class=\"mermaid\">{mermaid}</pre>`;\n",
    "    mermaid.run();\n",
    "}});\n",
    "</script>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00c643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
